# -*- coding: utf-8 -*-
"""Trabajo Bitcoin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q3gIYjP9hAruB2_gCAYuuMhLHu-w-aKY

# **Data wrangling**
"""

# importa librerías
from datetime import datetime
import time
import seaborn as sn
import json
import pandas as pd
import matplotlib.pyplot as plt

# crea función de descarga y de período de tiempo
def construct_download_url(
	ticker,
	period1,
	period2,
	interval='monthly'
):
	"""
	:period1 & period2: 'yyyy-mm-dd'
	:interval: {daily; weekly, monthly}
	"""
	def convert_to_seconds(period):
		datetime_value = datetime.strptime(period, '%Y-%m-%d')
		total_seconds = int(time.mktime(datetime_value.timetuple())) + 86400
		return total_seconds
	try:
		interval_reference = {'daily': '1d', 'weekly': '1wk', 'monthly': '1mo'}
		_interval = interval_reference.get(interval)
		if _interval is None:
			print('interval code is incorrect')
			return
		p1 = convert_to_seconds(period1)
		p2 = convert_to_seconds(period2)
		url = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={p1}&period2={p2}&interval={_interval}&filter=history'
		return url
	except Exception as e:
		print(e)
		return

# genera el dataset
query_url = construct_download_url('BTC-USD', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df = pd.read_csv(query_url)
df.set_index('Date', inplace=True)

# genera el dataset, X es el ticker de la paridad euro dolar
query_url1 = construct_download_url('EURUSD=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df1 = pd.read_csv(query_url1)
df1.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad libras dolar
query_url2 = construct_download_url('GBPUSD=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df2 = pd.read_csv(query_url2)
df2.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad yen vs dolar
query_url3 = construct_download_url('JPY=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df3 = pd.read_csv(query_url3)
df3.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad eth vs dolar
query_url4 = construct_download_url('ETH-USD', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df4 = pd.read_csv(query_url4)
df4.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad ltc vs dolar
query_url5 = construct_download_url('LTC-USD', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df5 = pd.read_csv(query_url5)
df5.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad xlm vs dolar
query_url6 = construct_download_url('XLM-USD', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df6 = pd.read_csv(query_url6)
df6.set_index('Date', inplace=True)
# genera el dataset, ahora con la paridad franco suizo vs dolar
query_url7 = construct_download_url('CHF=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df7 = pd.read_csv(query_url7)
df7.set_index('Date', inplace=True)
# genera el dataset, ahora con la paridad yuan vs dolar
query_url8 = construct_download_url('CNY=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df8 = pd.read_csv(query_url8)
df8.set_index('Date', inplace=True)

# genera el dataset, ahora con la paridad dolar canadiense vs dolar
query_url9 = construct_download_url('CADUSD=X', '2015-01-01', '2022-11-10', 'daily') #acá se elige la ventana de tiempo
df9 = pd.read_csv(query_url9)
df9.set_index('Date', inplace=True)

# guarda el dataset como CSV
df1.to_csv('Euro Prices.csv')
# guarda el dataset como CSV
df2.to_csv('British Pounds Prices.csv')
# guarda el dataset como CSV
df.to_csv('Bitcoin Historical Data.csv')
# guarda el dataset como CSV
df3.to_csv('Yen Prices.csv')
# guarda el dataset como CSV
df4.to_csv('Ethereum Prices.csv')
# guarda el dataset como CSV
df5.to_csv('Litecoin Prices.csv')
# guarda el dataset como CSV
df6.to_csv('Stellar Prices.csv')
# guarda el dataset como CSV
df7.to_csv('CHF Prices.csv')
# guarda el dataset como CSV
df8.to_csv('CNY Prices.csv')
# guarda el dataset como CSV
df9.to_csv('CAD Prices.csv')

# guarda el dataset como JSON file
with open('BTC-USD.json', 'w') as f:
	f.write(json.dumps(df.T.to_dict(), indent=4))

# generamos dataframe consolidado y exportamos a excel
df_consolidado = pd.concat([df,df1,df2,df3,df4,df5,df6,df7,df8,df9], axis = 1)
df_consolidado.to_excel("excel_consolidado.xlsx")

from google.colab import drive
drive.mount('/content/drive')

df_final = pd.read_excel("/content/drive/MyDrive/Papers/Paper 1 - Forecasting BTC/Colaboratory/excel_consolidado (2).xlsx")
describe= df_final.describe().transpose()
describe.to_excel("stats.xlsx")

excel = pd.read_excel("Input.xlsx")

excel.describe().to_excel("Datos.xlsx")

plt.figure(figsize=(8,8))
corrMatrix = excel.corr()
sn.heatmap(corrMatrix, annot=True)
plt.show()

# Raw Package
import numpy as np
import pandas as pd
!pip install yfinance

#Data Source
import yfinance as yf

#Data viz
import plotly.graph_objs as go

# Get Bitcoin data
data = yf.download(tickers='ETH-USD', period = '22h', interval = '15m')

#declare figure
fig = go.Figure()

#Candlestick
fig.add_trace(go.Candlestick(x=data.index,
                open=data['Open'],
                high=data['High'],
                low=data['Low'],
                close=data['Close'], name = 'market data'))

# Add titles
fig.update_layout(
    title='Bitcoin live share price evolution',
    yaxis_title='Bitcoin Price (kUS Dollars)')

# X-Axes
fig.update_xaxes(
    rangeslider_visible=True,
    rangeselector=dict(
        buttons=list([
            dict(count=15, label="15m", step="minute", stepmode="backward"),
            dict(count=45, label="45m", step="minute", stepmode="backward"),
            dict(count=1, label="HTD", step="hour", stepmode="todate"),
            dict(count=6, label="6h", step="hour", stepmode="backward"),
            dict(step="all")
        ])
    )
)

#Show
fig.show()

!pip install scalecast

!pip install pmdarima

import pandas as pd
import numpy as np
from scalecast.Forecaster import Forecaster
from pmdarima import auto_arima
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(rc={'figure.figsize':(14,7)})

df = pd.read_excel('/content/drive/MyDrive/Papers/Paper 1 - Forecasting BTC/Colaboratory/excel_consolidado (2).xlsx')
f = Forecaster(y=df['BTC'],current_dates=df['Date'])

f.generate_future_dates(12) # 12-month forecast horizon
f.set_test_length(.2) # 20% test set
f.set_estimator('arima') # set arima
f.manual_forecast(call_me='arima1') # forecast with arima

f.plot_test_set(ci=True) # view test results
plt.title('ARIMA Test-Set Performance',size=14)
plt.show()

!pip install statsmodels

import warnings
import itertools
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Defaults
plt.rcParams['figure.figsize'] = (20.0, 10.0)
plt.rcParams.update({'font.size': 12})
plt.style.use('ggplot')

from statsmodels.tsa.stattools import adfuller

test_result=adfuller(df_final['BTC'])

def adfuller_test(sales):
    result=adfuller(sales)
    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations']
    for value,label in zip(result,labels):
        print(label+' : '+str(value) )

if result[1] <= 0.05:
    print("strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary")
else:
    print("weak evidence against null hypothesis,indicating it is non-stationary ")

adfuller_test(df_final['BTC'])

# For non-seasonal data
#p=1, d=1, q=0 or 1

from statsmodels.tsa.arima_model import ARIMA
model=ARIMA(df_final['BTC'],order=(2,1,1))
model_fit=model.fit()
model_fit.summary()

# For non-seasonal data
#p=1, d=1, q=0 or 1

df_final['forecast']=model_fit.predict(start=90,end=103,dynamic=True)
df_final[['BTC','forecast']].plot(figsize=(12,8))

import statsmodels.api as sm
model=sm.tsa.statespace.SARIMAX(df_final['BTC'],order=(1, 1, 1),seasonal_order=(1,1,1,12))
results=model.fit()
df_final['BTC']=results.predict(start=90,end=103,dynamic=True)
df_final[['BTC','forecast']].plot(figsize=(12,8))

!pip3 uninstall statsmodels

!pip3 install numpy scipy patsy pandas

!pip3 install statsmodels

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from pandas import datetime as dt
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
#from statsmodels.api import tsa

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error



from pandas.plotting import autocorrelation_plot

autocorrelation_plot(df_final["BTC"])

prices = df_final.BTC
price_diff = prices.diff(7).dropna() 

plt.figure(figsize=(16,3))
plt.plot(price_diff, "-o", color='orange')

time_series = price_diff

lags = [7, 8, 10, 14, 17, 28, 30, 60, 90, 180]

def organize_data(to_forecast, window, horizon=1):
    
    shape = to_forecast.shape[:-1] + (to_forecast.shape[-1] - window + 1, window)
    strides = to_forecast.strides + (to_forecast.strides[-1],)
    X = np.lib.stride_tricks.as_strided(to_forecast,
                                        shape=shape,
                                        strides=strides)
    y = np.array([X[i+horizon][-1] for i in range(len(X)-horizon)])
    return X[:-horizon], y

lag = 90
X, y = organize_data(time_series, lag)

lr = LinearRegression()
lr_fit = lr.fit(X, y)
lr_prediction = lr_fit.predict(X)

plt.figure(figsize=(16, 4))
plt.plot(time_series.values, '-o', color='teal')
plt.plot(np.arange(lag, len(time_series)), lr_prediction, '-o', label='prediction', color='orange')
plt.legend(fontsize=12);

print('MAE = {0:.3f}'.format(mean_absolute_error(time_series[lag:], lr_prediction)))
print('MAE2 = {0:.3f}'.format(mean_absolute_error(time_series[-90:], lr_prediction[-90:]))) #for the last 90 days only

"""# ARIMA"""

import pandas as pd
excel = pd.read_excel("Input.xlsx")

import statsmodels.api as sm

df = excel.set_index( "Date")
df

excel['Date'] = pd.to_datetime(excel['Date'], errors='coerce')

df  = excel[["Bitcoin","Date"]]

df = df.set_index( "Date")

df = df.resample("D").mean()
df_month = df.resample('M').mean()

import matplotlib.pyplot as plt
plt.plot()
plt.plot(df, '-', label='By Days')
plt.legend()

plt.figure(figsize=[20,13])

sm.tsa.seasonal_decompose(df_month).plot()
print("Dickey–Fuller test: p=%f" % sm.tsa.stattools.adfuller(df)[1])

plt.savefig("Descomposión.jpg")
plt.show()

"""Las series, basados en el test de Dickey Fuller **no son estacionarias**"""

from scipy import stats

df_month

"""## Transformaciones de Box-Cox

Se utilizan para corregir problemas de sesgo y estacionariedad
"""

# Box-Cox Transformations
df_month['Weighted_Price_box'], lmbda = stats.boxcox(df_month.Bitcoin)
print("Dickey–Fuller test: p=%f" % sm.tsa.stattools.adfuller(df_month.Bitcoin)[1])

# Seasonal differentiation
df_month['prices_box_diff2'] = df_month.Weighted_Price_box - df_month.Weighted_Price_box.shift(12)
print("Dickey–Fuller test: p=%f" % sm.tsa.stattools.adfuller(df_month.prices_box_diff[12:])[1])

# Regular differentiation
df_month['serie_diferenciada'] = df_month.prices_box_diff - df_month.prices_box_diff.shift(1)
plt.figure(figsize=(15,7))

# STL-decomposition
sm.tsa.seasonal_decompose(df_month.serie_diferenciada[13:]).plot()   
print("Dickey–Fuller test: p=%f" % sm.tsa.stattools.adfuller(df_month.prices_box_diff2[13:])[1])
plt.savefig("Descomposición2")
plt.show()

"""Luego de realizar diferenciaciones y transformaciones de distintos tipos, las series ahora tienen un comportamiento **estacionario**"""

# Initial approximation of parameters using Autocorrelation and Partial Autocorrelation Plots
plt.figure(figsize=(15,7))
ax = plt.subplot(111)

sm.graphics.tsa.plot_acf(df_month.prices_box_diff2[13:].values.squeeze(), lags=30, ax=ax)
plt.savefig("Correlograma.jpg")

plt.figure(figsize=(15,7))
ax = plt.subplot(111)
sm.graphics.tsa.plot_pacf(df_month.prices_box_diff2[13:].values.squeeze(), lags=30, ax=ax)
plt.tight_layout()
plt.savefig("Función de Autocorrelación Pacial.jpg")
plt.show()

from itertools import product
import warnings

# Initial approximation of parameters
Qs = range(0, 2)
qs = range(0, 3)
Ps = range(0, 3)
ps = range(0, 3)
D=1
d=1
parameters = product(ps, qs, Ps, Qs)
parameters_list = list(parameters)
len(parameters_list)

# Model Selection
results = []
best_aic = float("inf")
warnings.filterwarnings('ignore')
for param in parameters_list:
    try:
        model=sm.tsa.statespace.SARIMAX(df_month.Weighted_Price_box, order=(param[0], d, param[1]), 
                                        seasonal_order=(param[2], D, param[3], 12)).fit(disp=-1)
    except ValueError:
        print('wrong parameters:', param)
        continue
    aic = model.aic
    bic = model.bic
    if aic < best_aic:
        best_model = model
        best_aic = aic
        best_param = param
    results.append([param, model.aic,model.bic])

# Best Models
result_table = pd.DataFrame(results)
result_table.columns = ['parameters', 'aic','bic']
print(result_table.sort_values(by = 'aic', ascending=True).head())
print(best_model.summary())

"""## Análisis de los residuos """

# STL-decomposition
plt.figure(figsize=(15,7))
plt.subplot(211)
best_model.resid[13:].plot()
plt.ylabel(u'Residuals')
ax = plt.subplot(212)
sm.graphics.tsa.plot_acf(best_model.resid[13:].values.squeeze(), lags=48, ax=ax)

print("Dickey–Fuller test:: p=%f" % sm.tsa.stattools.adfuller(best_model.resid[13:])[1])

plt.tight_layout()
plt.savefig("Grafico.jpg")
plt.show()

from statsmodels.tsa.stattools import acf, pacf
import numpy as np
lag_acf = acf(df["Bitcoin"].values, nlags = 20)
#lag_pacf = pacf(log_air_passengers_diff.values, nlags = 20)

# Inverse Box-Cox Transformation Function
def invboxcox(y,lmbda):
    if lmbda == 0:
        return(np.exp(y))
    else:
        return(np.exp(np.log(lmbda*y+1)/lmbda))

# Prediction
df_month2 = df_month[['Bitcoin']]
date_list = [datetime(2017, 6, 30), datetime(2017, 7, 31), datetime(2017, 8, 31), datetime(2017, 9, 30), 
             datetime(2017, 10, 31), datetime(2017, 11, 30), datetime(2017, 12, 31), datetime(2018, 1, 31),
             datetime(2018, 1, 28),]
future = pd.DataFrame(index=date_list, columns= df_month.columns)
df_month2 = pd.concat([df_month2, future])
df_month2['forecast'] = invboxcox(best_model.predict(start=0, end=90), lmbda)
plt.figure(figsize=(15,7))
df_month2.Bitcoin.plot()
df_month2.forecast.plot(color='r', ls='--', label='Predicción Precio Bitcoin mediante ARIMA')
plt.legend()
plt.title('Movimiento del precio del Bitcoin')
plt.ylabel('Dólar por Bitcoin')
plt.savefig("Proyección.jpg")
plt.show()

#Proyeccion de un rango de fechas con la regresión anterior
df_month2 = df_month[['Bitcoin']]
date_list = pd.period_range(
    '2015-01-03',
    '2022-11-10'
)
future = pd.DataFrame(index=date_list, columns= df_month.columns)
df_month2 = pd.concat([df_month2, future])
df_month2['forecast'] = invboxcox(best_model.predict(start=0, end=90), lmbda)
df_month2.forecast.to_excel("Proyección.xlsx")

"""# Modelo Prophet"""

!pip install numpy cython
!pip install matplotlib seaborn scipy pandas
!pip install pystan
!pip install fbprophet

!conda install -c conda-forge fbprophet -y

!pip install --upgrade plotly

!pip install prophet

# Python
df = pd.read_csv('https://raw.githubusercontent.com/facebook/prophet/main/examples/example_wp_log_peyton_manning.csv')
df.head()

from prophet import Prophet
import seaborn as sns
from datetime import datetime, timedelta

"""Arrancamos con tomar las series para iniciar con el analisis exploratorio"""

# reset index to get date_time as a column
prophet_df = pd.read_excel("Input.xlsx")

# prepare the required dataframe
prophet_df.rename(columns={'Date':'ds','Bitcoin':'y'},inplace=True)
prophet_df = prophet_df[['ds','y']]

prophet_df.head()

sns.set(style = "ticks")# to format into seaborn 
c = '#386B7F' # basic color for plots

# plot daily sales
ax = prophet_df.set_index('ds').plot(figsize = (12, 4), color = c)
ax.set_ylabel('Precio del Bitcoin')
ax.set_xlabel('Tiempo')
plt.show()



"""Definimos el poercentaje de accuracy con el que nos desenvolveremos en el resto del modelo"""

TRAIN_PERCENT = 0.8

"""Preparamos datos de testeo y entrenamiento"""

# prepare train and test sets
train_size = int(prophet_df.shape[0]*TRAIN_PERCENT)
train_df = prophet_df.iloc[:train_size]
test_df = prophet_df.iloc[train_size+1:]

test_df

"""Preparación del modelo prophet"""

# build a prophet model
pro_model = Prophet()

# fit the model
pro_model.fit(train_df)

# prepare a future dataframe
test_dates = pro_model.make_future_dataframe(periods=test_df.shape[0], include_history = True)

# forecast values
forecast_df = pro_model.predict(test_dates)

forecast_df.to_excel("Proyeccion.xlsx")

pro_model.plot(forecast_df)
plt.show()

# plot against true data
plt.plot(forecast_df.yhat,c='r',label='Forecast')
plt.plot(forecast_df.yhat_lower.iloc[train_size+1:],
         linestyle='--',c='b',alpha=0.3,
         label='Confidence Interval')
plt.plot(forecast_df.yhat_upper.iloc[train_size+1:],
         linestyle='--',c='b',alpha=0.3,
         label='Confidence Interval')
plt.plot(prophet_df.y,c='g',label='True Data')
plt.legend()
plt.title('Prophet Model Forecast Against True Data')
plt.show()